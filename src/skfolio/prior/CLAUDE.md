[æ ¹ç›®å½•](../../../CLAUDE.md) > [src](../../) > [skfolio](../) > **prior**

# prior - å…ˆéªŒä¿¡æ¯é›†æˆæ¨¡å—

## æ¨¡å—èŒè´£

prior æ¨¡å—æä¾›äº†å°†æŠ•èµ„è§‚ç‚¹ã€å‡è¡¡æ¨¡å‹å’Œå…ˆéªŒä¿¡æ¯é›†æˆåˆ°æŠ•èµ„ç»„åˆä¼˜åŒ–ä¸­çš„å·¥å…·ã€‚è¿™äº›æ–¹æ³•å…è®¸æŠ•èµ„è€…ç»“åˆé‡åŒ–åˆ†æã€å¸‚åœºå‡è¡¡å’Œä¸»è§‚è§‚ç‚¹ï¼Œç”Ÿæˆæ›´åŠ ç¨³å¥å’Œåˆç†çš„æœŸæœ›æ”¶ç›Šä¼°è®¡ï¼Œç‰¹åˆ«é€‚ç”¨äº Black-Litterman æ¨¡å‹ã€ç†µæ± åŒ–ç­‰ç°ä»£æŠ•èµ„ç»„åˆç†è®ºã€‚

## æ¨¡å—ç»“æ„

```
prior/
â”œâ”€â”€ __init__.py              # æ¨¡å—å…¥å£
â”œâ”€â”€ _base.py                # BasePrior åŸºç±»
â”œâ”€â”€ _empirical.py           # ç»éªŒå…ˆéªŒ
â”œâ”€â”€ _black_litterman.py     # Black-Litterman æ¨¡å‹
â”œâ”€â”€ _entropy_pooling.py     # ç†µæ± åŒ–æ–¹æ³•
â”œâ”€â”€ _opinion_pooling.py     # è§‚ç‚¹æ± åŒ–
â”œâ”€â”€ _factor_model.py        # å› å­æ¨¡å‹
â””â”€â”€ _synthetic_data.py      # åˆæˆæ•°æ®ç”Ÿæˆ
```

## å…¥å£ä¸å¯åŠ¨

æ¨¡å—å¯¼å‡ºäº†æ‰€æœ‰å…ˆéªŒæ¨¡å‹ï¼š

```python
from skfolio.prior import (
    # åŸºç±»
    BasePrior,
    ReturnDistribution,
    BaseLoadingMatrix,

    # å…ˆéªŒæ¨¡å‹
    EmpiricalPrior,           # ç»éªŒå…ˆéªŒ
    BlackLitterman,          # Black-Litterman æ¨¡å‹
    EntropyPooling,          # ç†µæ± åŒ–
    OpinionPooling,          # è§‚ç‚¹æ± åŒ–
    FactorModel,             # å› å­æ¨¡å‹

    # å› å­æ¨¡å‹å·¥å…·
    LoadingMatrixRegression,

    # åˆæˆæ•°æ®
    SyntheticData,
)
```

## å¯¹å¤–æ¥å£

### BasePrior åŸºç±»

æ‰€æœ‰å…ˆéªŒæ¨¡å‹çš„åŸºç±»ï¼š

```python
class BasePrior(BaseEstimator, TransformerMixin):
    """å…ˆéªŒæ¨¡å‹åŸºç±»"""

    def fit(self, X, y=None, **fit_params):
        """æ‹Ÿåˆå…ˆéªŒæ¨¡å‹"""

    def set_prior_model(self, prior_model):
        """è®¾ç½®å…ˆéªŒæ¨¡å‹å‚æ•°"""

    def get_prior_mu(self):
        """è·å–å…ˆéªŒæœŸæœ›æ”¶ç›Š"""

    def get_prior_covariance(self):
        """è·å–å…ˆéªŒåæ–¹å·®çŸ©é˜µ"""

    def compute_posterior(self, views):
        """è®¡ç®—åéªŒåˆ†å¸ƒ"""
```

### EmpiricalPrior

åŸºäºå†å²æ•°æ®çš„ç»éªŒå…ˆéªŒï¼š

```python
empirical = EmpiricalPrior(
    mu_estimator=EmpiricalMu(),         # æœŸæœ›æ”¶ç›Šä¼°è®¡å™¨
    covariance_estimator=EmpiricalCovariance(),  # åæ–¹å·®ä¼°è®¡å™¨
    risk_free_rate=0.0,                # æ— é£é™©åˆ©ç‡
    min_n_samples=None,                # æœ€å°æ ·æœ¬æ•°
    window_size=None,                  # æ»šåŠ¨çª—å£
)

# æ‹Ÿåˆå…ˆéªŒ
empirical.fit(returns)
prior_mu = empirical.prior_mu_
prior_cov = empirical.prior_covariance_
```

### BlackLitterman

Black-Litterman æ¨¡å‹ï¼Œç»“åˆå¸‚åœºå‡è¡¡å’ŒæŠ•èµ„è€…è§‚ç‚¹ï¼š

```python
bl = BlackLitterman(
    prior=EmpiricalPrior(),            # å…ˆéªŒæ¨¡å‹
    risk_aversion=1.0,                 # é£é™©åŒæ¶ç³»æ•°
    tau=0.05,                         # ä¸ç¡®å®šæ€§æ ‡é‡
    equilibrium="implied",             # å‡è¡¡ç±»å‹
)

# æ·»åŠ è§‚ç‚¹
views = np.array([
    [1, 0, -1, 0],    # èµ„äº§1é¢„æœŸæ¯”èµ„äº§3é«˜2%
    [0, 1, 0, -1],    # èµ„äº§2é¢„æœŸæ¯”èµ„äº§4é«˜1%
])
views_confidences = np.array([0.5, 0.3])  # è§‚ç‚¹ç½®ä¿¡åº¦

bl.set_views(views, views_confidences)
bl.fit(returns)
```

### EntropyPooling

ç†µæ± åŒ–æ–¹æ³•ï¼ŒåŸºäºä¿¡æ¯è®ºçš„ä¸€è‡´æ€§è§‚ç‚¹é›†æˆï¼š

```python
ep = EntropyPooling(
    prior=EmpiricalPrior(),            # å…ˆéªŒåˆ†å¸ƒ
    confidence=0.95,                   # ç½®ä¿¡æ°´å¹³
    bounds=None,                       # è¾¹ç•Œçº¦æŸ
    minimize="relative_entropy",       # æœ€å°åŒ–ç›®æ ‡
)

# è®¾ç½®çº¿æ€§è§‚ç‚¹
linear_views = {
    "A": np.array([[1, -1, 0, 0]]),   # èµ„äº§1 > èµ„äº§2
    "b": np.array([0.02]),            # å·®å€¼ä¸º2%
    "inequality": True,               # ä¸ç­‰å¼çº¦æŸ
}

ep.set_linear_views(linear_views)
ep.fit(returns)
```

### FactorModel

å¤šå› å­æ¨¡å‹ï¼Œå°†èµ„äº§æ”¶ç›Šåˆ†è§£ä¸ºå› å­æ”¶ç›Šï¼š

```python
factor_model = FactorModel(
    factor_returns=None,              # å› å­æ”¶ç›Šæ•°æ®
    loading_matrix=None,              # å› å­è½½è·çŸ©é˜µ
    factor_prior=EmpiricalPrior(),    # å› å­å…ˆéªŒ
    idiosyncratic_prior=None,         # ç‰¹å¼‚æ€§é£é™©å…ˆéªŒ
)

# ä½¿ç”¨å›å½’ä¼°è®¡å› å­è½½è·
loading_matrix = LoadingMatrixRegression(
    method="ols",                     # å›å½’æ–¹æ³•
    intercept=True,                   # åŒ…å«æˆªè·
    regularizer=None,                 # æ­£åˆ™åŒ–
)

factor_model.loading_matrix = loading_matrix
factor_model.fit(returns, factor_returns)
```

### OpinionPooling

è§‚ç‚¹æ± åŒ–æ–¹æ³•ï¼Œçº¿æ€§ç»„åˆå¤šä¸ªè§‚ç‚¹ï¼š

```python
op = OpinionPooling(
    priors=[EmpiricalPrior(), FactorModel()],  # å¤šä¸ªå…ˆéªŒ
    weights=[0.6, 0.4],                       # ç»„åˆæƒé‡
    pooling_method="linear",                   # æ± åŒ–æ–¹æ³•
)

op.fit(returns)
```

## å…³é”®ä¾èµ–ä¸é…ç½®

### æ ¸å¿ƒä¾èµ–
- **numpy**: æ•°å€¼è®¡ç®—
- **pandas**: æ•°æ®å¤„ç†
- **scipy**: ä¼˜åŒ–å’Œç»Ÿè®¡
- **cvxpy**: å‡¸ä¼˜åŒ–æ±‚è§£

### ä¼˜åŒ–é…ç½®
```python
# Black-Litterman ä¼˜åŒ–é€‰é¡¹
bl.optimizer_kwargs = {
    "solver": "CLARABEL",
    "verbose": True,
    "max_iters": 1000,
}
```

### å¹¶è¡Œå¤„ç†
- æ”¯æŒå¤šè§‚ç‚¹å¹¶è¡Œè®¡ç®—
- æ‰¹é‡å¤„ç†å¤šä¸ªåœºæ™¯

## æ•°æ®æ¨¡å‹

### è§‚ç‚¹çŸ©é˜µæ ¼å¼
```python
P: np.ndarray  # shape (n_views, n_assets) - è§‚ç‚¹è½½è·çŸ©é˜µ
q: np.ndarray  # shape (n_views,) - è§‚ç‚¹æ”¶ç›Šå‘é‡
Omega: np.ndarray  # shape (n_views, n_views) - è§‚ç‚¹ä¸ç¡®å®šæ€§çŸ©é˜µ
```

### å› å­æ¨¡å‹æ ¼å¼
```python
B: np.ndarray  # shape (n_assets, n_factors) - å› å­è½½è·
F: np.ndarray  # shape (n_periods, n_factors) - å› å­æ”¶ç›Š
D: np.ndarray  # shape (n_assets,) - ç‰¹å¼‚æ€§é£é™©
```

### è¿”å›åˆ†å¸ƒ
```python
ReturnDistribution = namedtuple(
    "ReturnDistribution",
    ["mu", "covariance", "returns"]  # æœŸæœ›æ”¶ç›Šã€åæ–¹å·®ã€æ”¶ç›Šæ•°æ®
)
```

## å…ˆéªŒæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **EmpiricalPrior** | ç®€å•ç›´è§‚ | å¿½è§†å…ˆéªŒä¿¡æ¯ | åŸºå‡†æ¨¡å‹ |
| **BlackLitterman** | ç†è®ºå®Œå¤‡ | å‚æ•°æ•æ„Ÿ | è§‚ç‚¹æ˜ç¡® |
| **EntropyPooling** | çµæ´»çº¦æŸ | è®¡ç®—å¤æ‚ | å¤æ‚è§‚ç‚¹ |
| **FactorModel** | ç»æµå«ä¹‰ | å› å­é€‰æ‹© | å¤šå› å­åˆ†æ |
| **OpinionPooling** | ç»„åˆçµæ´» | æƒé‡ä¸»è§‚ | å¤šæºä¿¡æ¯ |

## æµ‹è¯•ä¸è´¨é‡

### æµ‹è¯•æ–‡ä»¶
- `tests/test_prior/test_empirical.py` - ç»éªŒå…ˆéªŒæµ‹è¯•
- `tests/test_prior/test_black_litterman.py` - Black-Litterman æµ‹è¯•
- `tests/test_prior/test_entropy_pooling.py` - ç†µæ± åŒ–æµ‹è¯•
- `tests/test_prior/test_factor_model.py` - å› å­æ¨¡å‹æµ‹è¯•
- `tests/test_prior/test_opinion_pooling.py` - è§‚ç‚¹æ± åŒ–æµ‹è¯•

### æµ‹è¯•è¦†ç›–
- âœ… å„ç§å…ˆéªŒæ¨¡å‹çš„æ­£ç¡®æ€§
- âœ… è§‚ç‚¹é›†æˆé€»è¾‘
- âœ… ä¼˜åŒ–æ±‚è§£ç¨³å®šæ€§
- âœ… è¾¹ç•Œæ¡ä»¶
- âœ… æ•°å€¼ç²¾åº¦

### æ€§èƒ½ä¼˜åŒ–
- å‘é‡åŒ–å®ç°
- ç¼“å­˜æœºåˆ¶
- ä½¿ç”¨é«˜æ•ˆæ±‚è§£å™¨

## å¸¸è§é—®é¢˜ (FAQ)

### Q: å¦‚ä½•é€‰æ‹©é£é™©åŒæ¶ç³»æ•°ï¼Ÿ
A:
```python
# åŸºäº Black-Litterman æ¨è
risk_aversion = 1 / (annual_return / annual_volatility**2)

# æˆ–ä½¿ç”¨å†å²ä¼°è®¡
risk_aversion = np.mean(returns) / np.var(returns) * 252
```

### Q: å¦‚ä½•è®¾ç½®è§‚ç‚¹ç½®ä¿¡åº¦ï¼Ÿ
A:
```python
# åŸºäºå†å²å‡†ç¡®æ€§
historical_errors = views - actual_returns
confidence = 1 / np.var(historical_errors)

# æˆ–åŸºäºä¸»è§‚åˆ¤æ–­
confidence = np.array([0.8, 0.6, 0.4])  # 80%, 60%, 40% ç½®ä¿¡åº¦
```

### Q: å¦‚ä½•å¤„ç†å› å­æ¨¡å‹ä¸­çš„ç¼ºå¤±æ•°æ®ï¼Ÿ
A:
```python
# ä½¿ç”¨ EM ç®—æ³•
factor_model = FactorModel(
    loading_matrix=LoadingMatrixRegression(
        method="em",  # æœŸæœ›æœ€å¤§åŒ–
        max_iter=100,
        tolerance=1e-6,
    )
)
```

### Q: å¦‚ä½•éªŒè¯å…ˆéªŒæ¨¡å‹ï¼Ÿ
A:
```python
# ä½¿ç”¨äº¤å‰éªŒè¯
from skfolio.model_selection import WalkForward

wf = WalkForward(train_size=504, test_size=252)
results = wf.evaluate(
    X=returns,
    models=[BlackLitterman(), EmpiricalPrior()]
)
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒå®ç°
- `_black_litterman.py` - Black-Litterman å®ç°
- `_entropy_pooling.py` - ç†µæ± åŒ–å®ç°
- `_factor_model.py` - å› å­æ¨¡å‹å®ç°
- `_base.py` - åŸºç±»å’Œå·¥å…·å‡½æ•°

### é›†æˆæ–‡ä»¶
- `optimization/_base.py` - ä¼˜åŒ–å™¨ä½¿ç”¨å…ˆéªŒ
- `prior/_synthetic_data.py` - åˆæˆæ•°æ®ç”Ÿæˆ

### ç¤ºä¾‹æ–‡ä»¶
- `examples/mean_risk/plot_12_black_and_litterman.py` - Black-Litterman ç¤ºä¾‹
- `examples/entropy_pooling/plot_1_entropy_pooling.py` - ç†µæ± åŒ–ç¤ºä¾‹
- `examples/mean_risk/plot_13_factor_model.py` - å› å­æ¨¡å‹ç¤ºä¾‹

## å˜æ›´è®°å½• (Changelog)

### 2025-12-09 06:15:32 UTC - æ¨¡å—åˆå§‹åŒ–
- ğŸ“š **åˆ›å»ºæ¨¡å—æ–‡æ¡£**ï¼šå®Œæ•´è®°å½•äº† prior æ¨¡å—çš„åŠŸèƒ½
- ğŸ—ï¸ **æ¨¡å‹åˆ†æ**ï¼šè¯¦ç»†è¯´æ˜äº† Black-Littermanã€ç†µæ± åŒ–ã€å› å­æ¨¡å‹ç­‰
- ğŸ“Š **å‚æ•°é…ç½®**ï¼šè®°å½•äº†é£é™©åŒæ¶ã€è§‚ç‚¹ç½®ä¿¡åº¦ç­‰å…³é”®å‚æ•°
- âœ… **æµ‹è¯•è¦†ç›–**ï¼šç¡®è®¤äº†å®Œæ•´çš„æµ‹è¯•è¦†ç›–

### æœ€æ–°åŠŸèƒ½
- æ”¹è¿›çš„ç†µæ± åŒ–ç®—æ³•
- æ”¯æŒæ›´å¤šå› å­æ¨¡å‹
- æ›´çµæ´»çš„è§‚ç‚¹æ ¼å¼
- å¹¶è¡Œè®¡ç®—ä¼˜åŒ–

---

## ä½¿ç”¨å»ºè®®

1. **æ¨¡å‹é€‰æ‹©**ï¼šæ ¹æ®ä¿¡æ¯ç±»å‹é€‰æ‹©åˆé€‚çš„å…ˆéªŒæ¨¡å‹
2. **å‚æ•°æ ¡å‡†**ï¼šä½¿ç”¨å†å²æ•°æ®æ ¡å‡†å…³é”®å‚æ•°
3. **è§‚ç‚¹è´¨é‡**ï¼šç¡®ä¿è§‚ç‚¹çš„åˆç†æ€§å’Œä¸€è‡´æ€§
4. **æ•æ„Ÿæ€§åˆ†æ**ï¼šæµ‹è¯•å‚æ•°å˜åŒ–çš„å½±å“
5. **ç¨³å¥æ€§**ï¼šä½¿ç”¨å¤šç§å…ˆéªŒæ¨¡å‹æ¯”è¾ƒç»“æœ

## æ‰©å±•å¼€å‘

æ·»åŠ è‡ªå®šä¹‰å…ˆéªŒï¼š

```python
class CustomPrior(BasePrior):
    def __init__(self, param1=1.0):
        super().__init__()
        self.param1 = param1

    def fit(self, X, y=None):
        # å®ç°è‡ªå®šä¹‰å…ˆéªŒä¼°è®¡
        self.prior_mu_ = self._estimate_mu(X)
        self.prior_covariance_ = self._estimate_cov(X)
        return self
```

## æœ€ä½³å®è·µ

1. **è§‚ç‚¹æ¥æº**ï¼šç¡®ä¿è§‚ç‚¹æœ‰å……åˆ†çš„æ•°æ®æˆ–ç†è®ºæ”¯æ’‘
2. **ç½®ä¿¡åº¦**ï¼šå®¢è§‚è¯„ä¼°è§‚ç‚¹çš„å¯é æ€§
3. **å‚æ•°è°ƒä¼˜**ï¼šä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜å‚æ•°
4. **ç»“æœéªŒè¯**ï¼šæ£€æŸ¥åéªŒåˆ†å¸ƒçš„åˆç†æ€§
5. **é£é™©æ§åˆ¶**ï¼šè€ƒè™‘æ¨¡å‹é£é™©å’Œå‚æ•°ä¸ç¡®å®šæ€§